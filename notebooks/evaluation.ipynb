{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.evaluation import evaluate_outputs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'gemma-3-4b-it',\n",
    "    'gemma-3-12b-it',\n",
    "    'gemma-3-27b-it',\n",
    "    'Llama-3.1-8B-Instruct',\n",
    "    'Llama-3.1-70B-Instruct',\n",
    "    'Llama-3.2-1B-Instruct',\n",
    "    'Llama-3.2-3B-Instruct',\n",
    "    'Llama-3.3-70B-Instruct',\n",
    "    'Qwen2.5-0.5B-Instruct',\n",
    "    'Qwen2.5-1.5B-Instruct',\n",
    "    'Qwen2.5-3B-Instruct',\n",
    "    'Qwen2.5-7B-Instruct',\n",
    "    'Qwen2.5-72B-Instruct',\n",
    "    'Mistral-Large-Instruct-2411',\n",
    "]\n",
    "\n",
    "techniques = [\n",
    "    'chatgpt_template'\n",
    "]\n",
    "\n",
    "languages = [\n",
    "    'ara',\n",
    "    'deu',\n",
    "    'eng',\n",
    "    'fra',\n",
    "    'hi',\n",
    "    'mr',\n",
    "    'msa',\n",
    "    'pa',\n",
    "    'pol',\n",
    "    'por',\n",
    "    'spa',\n",
    "    'ta',\n",
    "    'tha'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['model', 'technique'] + languages)\n",
    "\n",
    "for model in models:\n",
    "    for technique in techniques:\n",
    "        results_df = pd.concat([results_df, pd.DataFrame(\n",
    "            columns=['model', 'technique'] + languages,\n",
    "            data=[[model, technique] + [None] * len(languages)]\n",
    "        )])\n",
    "        for language in languages:\n",
    "            df = pd.read_csv(f'../results/{model}/{technique}/dev-{language}_generated.csv')\n",
    "            \n",
    "            metrics = evaluate_outputs(\n",
    "                df['generated_output'].tolist(),\n",
    "                df['normalized claim'].tolist()\n",
    "            )\n",
    "            meteor = metrics['meteor']\n",
    "            \n",
    "            results_df.loc[\n",
    "                (results_df['model'] == model) & (results_df['technique'] == technique),\n",
    "                language\n",
    "            ] = meteor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df[['model'] + languages].to_markdown(\n",
    "    index=False,\n",
    "    tablefmt='github',\n",
    "    floatfmt=\".3f\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
